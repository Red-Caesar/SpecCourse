models: [
    # "meta-llama/Llama-3.2-1B-Instruct",
    "meta-llama/Llama-3.1-8B-Instruct",
    # "meta-llama/Llama-3.1-70B-Instruct",
  ]

num_calibration_samples: 512
max_sequence_length: 2048

quant_methods: [
  {
    "setup_name": "SmoothQuant + GPTQ (FP8)",
    "model_suffix": "FP8",
    "recipe": [
      "SmoothQuantModifier": {
        "smoothing_strength": 0.8
      },
      "GPTQModifier": {
        "scheme": "FP8",
        "ignore": ["lm_head"],
        "targets": "Linear"
      },
    ],
  },
  # {
  #   "setup_name": "SmoothQuant + GPTQ (INT8)",
  #   "model_suffix": "INT8",
  #   "recipe": [
  #     "SmoothQuantModifier": {
  #       "smoothing_strength": 0.8
  #     },
  #     "GPTQModifier": {
  #       "scheme": "W8A8",
  #       "ignore": ["lm_head"],
  #       "targets": "Linear"
  #     },
  #   ],
  # },
  # {
  #   "setup_name": "SmoothQuant + GPTQ (INT4)",
  #   "model_suffix": "INT4",
  #   "recipe": [
  #     "SmoothQuantModifier": {
  #       "smoothing_strength": 0.8
  #     },
  #     "GPTQModifier": {
  #       "scheme": "W4A8",
  #       "ignore": ["lm_head"],
  #       "targets": "Linear"
  #     },
  #   ],
  # },
  # {
  #   "setup_name": "SparseGPT",
  #   "model_suffix": "sparse_05",
  #   "recipe": [
  #     "SparseGPTModifier": {
  #       "sparsity": 0.5,
  #       "mask_structure": "2:4",
  #       "targets": ["re:model.layers.\\d*$"]
  #     },
  #   ],
  # },
  {
    "setup_name": "SparseGPT + SmoothQuant + GPTQ (FP8)",
    "model_suffix": "sparse_05_FP8",
    "recipe": [
      "SparseGPTModifier": {
        "sparsity": 0.5,
        "mask_structure": "2:4",
        "targets": ["re:model.layers.\\d*$"]
      },
      "SmoothQuantModifier": {
        "smoothing_strength": 0.8
      },
      "GPTQModifier": {
        "scheme": "FP8",
        "ignore": ["lm_head"],
        "targets": "Linear"
      },
    ],
  },
  {
    "setup_name": "SparseGPT + SmoothQuant + GPTQ (INT8)",
    "model_suffix": "sparse_05_INT8",
    "recipe": [
      "SparseGPTModifier": {
        "sparsity": 0.5,
        "mask_structure": "2:4",
        "targets": ["re:model.layers.\\d*$"]
      },
      "SmoothQuantModifier": {
        "smoothing_strength": 0.8
      },
      "GPTQModifier": {
        "scheme": "W8A8",
        "ignore": ["lm_head"],
        "targets": "Linear"
      },
    ],
  },
  {
    "setup_name": "SparseGPT + SmoothQuant + GPTQ (INT4)",
    "model_suffix": "sparse_05_INT4",
    "recipe": [
      "SparseGPTModifier": {
        "sparsity": 0.5,
        "mask_structure": "2:4",
        "targets": ["re:model.layers.\\d*$"]
      },
      "SmoothQuantModifier": {
        "smoothing_strength": 0.8
      },
      "GPTQModifier": {
        "scheme": "W4A8",
        "ignore": ["lm_head"],
        "targets": "Linear"
      },
    ],
  },
]
